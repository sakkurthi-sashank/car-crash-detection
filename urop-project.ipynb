{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-23T14:55:22.435223Z","iopub.status.busy":"2023-11-23T14:55:22.434807Z","iopub.status.idle":"2023-11-23T14:55:40.723306Z","shell.execute_reply":"2023-11-23T14:55:40.721910Z","shell.execute_reply.started":"2023-11-23T14:55:22.435192Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import os\n","from os import *\n","import random\n","\n","from sklearn.utils import shuffle\n","import tensorflow as tf\n","\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image\n","from keras.preprocessing.image import load_img, img_to_array\n","from keras.layers import Dense, Flatten, Dropout, Activation, BatchNormalization, Conv2D, MaxPooling2D ,ZeroPadding2D, GlobalAveragePooling2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import SGD , Adam , Adadelta\n","from keras import backend as K\n","from keras import regularizers\n","from keras.regularizers import *\n","from keras.applications.resnet50 import ResNet50\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.utils import plot_model\n","from keras.callbacks import *\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T14:55:40.726567Z","iopub.status.busy":"2023-11-23T14:55:40.725875Z","iopub.status.idle":"2023-11-23T14:55:40.733226Z","shell.execute_reply":"2023-11-23T14:55:40.731962Z","shell.execute_reply.started":"2023-11-23T14:55:40.726529Z"},"trusted":true},"outputs":[],"source":["train = '../input/accident-detection-from-cctv-footage/data/train/'\n","val = '../input/accident-detection-from-cctv-footage/data/val/'\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T14:55:40.735929Z","iopub.status.busy":"2023-11-23T14:55:40.734967Z","iopub.status.idle":"2023-11-23T14:55:40.772096Z","shell.execute_reply":"2023-11-23T14:55:40.770892Z","shell.execute_reply.started":"2023-11-23T14:55:40.735878Z"},"trusted":true},"outputs":[],"source":["img_width,img_height = 300,300\n","\n","training_size = 600\n","epochs = 50\n","batch_size = 32\n","\n","if K.image_data_format()=='channels_first':\n","    input_shape = (3,img_width,img_height)\n","else:\n","    input_shape = (img_width,img_height,3)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T14:55:40.774861Z","iopub.status.busy":"2023-11-23T14:55:40.773830Z","iopub.status.idle":"2023-11-23T14:55:40.933136Z","shell.execute_reply":"2023-11-23T14:55:40.931916Z","shell.execute_reply.started":"2023-11-23T14:55:40.774805Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 791 images belonging to 2 classes.\n","Found 98 images belonging to 2 classes.\n"]}],"source":["train_datagen = ImageDataGenerator(\n","                rescale = 1./255.,\n","            \n",")\n","\n","train_gen = train_datagen.flow_from_directory(\n","            train,\n","            target_size = (img_width,img_height),\n","            batch_size = batch_size,\n","            color_mode = 'rgb',\n","            class_mode = 'binary'\n",")\n","\n","val_datagen =  ImageDataGenerator(\n","                rescale = 1./255.\n",")\n","validation_gen = val_datagen.flow_from_directory(\n","                 val,\n","                 target_size = (img_width,img_height),\n","                 batch_size = batch_size,\n","                 color_mode = 'rgb',\n","                 class_mode = 'binary')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T14:55:40.937828Z","iopub.status.busy":"2023-11-23T14:55:40.936753Z","iopub.status.idle":"2023-11-23T14:55:40.947835Z","shell.execute_reply":"2023-11-23T14:55:40.946974Z","shell.execute_reply.started":"2023-11-23T14:55:40.937776Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'Accident': 0, 'Non Accident': 1}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train_gen.class_indices\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T14:55:40.949406Z","iopub.status.busy":"2023-11-23T14:55:40.949075Z","iopub.status.idle":"2023-11-23T14:55:41.506372Z","shell.execute_reply":"2023-11-23T14:55:41.505182Z","shell.execute_reply.started":"2023-11-23T14:55:40.949379Z"},"trusted":true},"outputs":[],"source":["model = Sequential()\n","\n","model.add(Conv2D (32,(3,3),input_shape=(300,300,3)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D (64,(3,3)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D (128,(3,3)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D (256,(3,3)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(128))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.1))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T14:55:41.508211Z","iopub.status.busy":"2023-11-23T14:55:41.507834Z","iopub.status.idle":"2023-11-23T14:55:41.532360Z","shell.execute_reply":"2023-11-23T14:55:41.531148Z","shell.execute_reply.started":"2023-11-23T14:55:41.508179Z"},"trusted":true},"outputs":[],"source":["opt = Adam(lr = 0.001)\n","model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T14:55:41.534203Z","iopub.status.busy":"2023-11-23T14:55:41.533843Z","iopub.status.idle":"2023-11-23T14:55:41.617064Z","shell.execute_reply":"2023-11-23T14:55:41.615803Z","shell.execute_reply.started":"2023-11-23T14:55:41.534172Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 298, 298, 32)      896       \n","                                                                 \n"," activation (Activation)     (None, 298, 298, 32)      0         \n","                                                                 \n"," batch_normalization (Batch  (None, 298, 298, 32)      128       \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 149, 149, 32)      0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 149, 149, 32)      0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 147, 147, 64)      18496     \n","                                                                 \n"," activation_1 (Activation)   (None, 147, 147, 64)      0         \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 147, 147, 64)      256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 73, 73, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_1 (Dropout)         (None, 73, 73, 64)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 71, 71, 128)       73856     \n","                                                                 \n"," activation_2 (Activation)   (None, 71, 71, 128)       0         \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 71, 71, 128)       512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 35, 35, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_2 (Dropout)         (None, 35, 35, 128)       0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 33, 33, 256)       295168    \n","                                                                 \n"," activation_3 (Activation)   (None, 33, 33, 256)       0         \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 33, 33, 256)       1024      \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 16, 16, 256)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_3 (Dropout)         (None, 16, 16, 256)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 65536)             0         \n","                                                                 \n"," dense (Dense)               (None, 128)               8388736   \n","                                                                 \n"," activation_4 (Activation)   (None, 128)               0         \n","                                                                 \n"," batch_normalization_4 (Bat  (None, 128)               512       \n"," chNormalization)                                                \n","                                                                 \n"," dropout_4 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 129       \n","                                                                 \n"," activation_5 (Activation)   (None, 1)                 0         \n","                                                                 \n","=================================================================\n","Total params: 8779713 (33.49 MB)\n","Trainable params: 8778497 (33.49 MB)\n","Non-trainable params: 1216 (4.75 KB)\n","_________________________________________________________________\n"]}],"source":["model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T14:55:41.618949Z","iopub.status.busy":"2023-11-23T14:55:41.618577Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","24/24 [==============================] - 136s 5s/step - loss: 0.9532 - accuracy: 0.6034 - val_loss: 1.5657 - val_accuracy: 0.6224\n","Epoch 2/50\n","24/24 [==============================] - 122s 5s/step - loss: 0.5761 - accuracy: 0.7009\n","Epoch 3/50\n","24/24 [==============================] - 122s 5s/step - loss: 0.5260 - accuracy: 0.7233\n","Epoch 4/50\n","24/24 [==============================] - 121s 5s/step - loss: 0.4556 - accuracy: 0.7813\n","Epoch 5/50\n","24/24 [==============================] - 123s 5s/step - loss: 0.3694 - accuracy: 0.8406\n","Epoch 6/50\n","24/24 [==============================] - 123s 5s/step - loss: 0.2989 - accuracy: 0.8709\n","Epoch 7/50\n","24/24 [==============================] - 123s 5s/step - loss: 0.2448 - accuracy: 0.9065\n","Epoch 8/50\n","24/24 [==============================] - 122s 5s/step - loss: 0.2976 - accuracy: 0.8709\n","Epoch 9/50\n","24/24 [==============================] - 122s 5s/step - loss: 0.2392 - accuracy: 0.8986\n","Epoch 10/50\n","24/24 [==============================] - 122s 5s/step - loss: 0.2146 - accuracy: 0.9157\n","Epoch 11/50\n","24/24 [==============================] - 122s 5s/step - loss: 0.1786 - accuracy: 0.9407\n","Epoch 12/50\n","24/24 [==============================] - 123s 5s/step - loss: 0.2013 - accuracy: 0.9196\n","Epoch 13/50\n","24/24 [==============================] - 123s 5s/step - loss: 0.1648 - accuracy: 0.9473\n","Epoch 14/50\n","24/24 [==============================] - 123s 5s/step - loss: 0.1572 - accuracy: 0.9433\n"]}],"source":["history = model.fit(train_gen,\n","                    steps_per_epoch = 24,\n","                    validation_data = validation_gen ,\n","                    validation_steps = 6,\n","                    epochs = 50,\n","                    verbose = 1)\n","\n","model.save('accident_detection_model.h5')\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":804753,"sourceId":1379553,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
